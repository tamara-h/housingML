{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-n2-lDFtDr__"
   },
   "source": [
    "# A multivariate regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ivs4mcy0DsAB"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing as pre\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "colab_type": "code",
    "id": "O34vkt_cDsAE",
    "outputId": "05f637d3-ee66-4871-811e-9c03d5c4ec31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "housing = pandas.read_csv('data/housing.csv')\n",
    "housing['1h_ocean'] = [1 if i=='<1H OCEAN' else 0 for i in housing.ocean_proximity.values]\n",
    "housing['island'] = [1 if i=='ISLAND' else 0 for i in housing.ocean_proximity.values]\n",
    "housing['inland'] = [1 if i=='INLAND' else 0 for i in housing.ocean_proximity.values]\n",
    "housing['near_ocean'] = [1 if i=='NEAR OCEAN' else 0 for i in housing.ocean_proximity.values]\n",
    "housing['near_bay'] = [1 if i=='NEAR BAY' else 0 for i in housing.ocean_proximity.values]\n",
    "housing.drop(columns=['ocean_proximity'], inplace=True)\n",
    "notna = housing.total_bedrooms.notna()\n",
    "model = lm.LinearRegression()\n",
    "model.fit(housing.total_rooms.values[notna].reshape(-1,1), housing.total_bedrooms.values[notna].reshape(-1,1))\n",
    "model.score(housing.total_rooms.values[notna].reshape(-1,1), housing.total_bedrooms.values[notna].reshape(-1,1))\n",
    "isna = housing.total_bedrooms.isna()\n",
    "missing_bedrooms = model.predict(housing.total_rooms.values[isna].reshape(-1,1))\n",
    "housing.total_bedrooms.loc[isna] = np.squeeze(missing_bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_housing = housing\n",
    "housing = tmp_housing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_boundaries(feature_values, num_buckets):\n",
    "    boundaries = np.arange(0, num_buckets + 1) / num_buckets\n",
    "    quantiles = feature_values.quantile(boundaries)\n",
    "    quantiles = [quantiles[q] for q in quantiles.keys()]\n",
    "    return zip(quantiles[:-1], quantiles[1:])\n",
    "\n",
    "def bucketize(data, columns):\n",
    "    for column, buckets in columns:\n",
    "        if data[column].dtypes == \"float64\":\n",
    "            ranges = get_bucket_boundaries(data[column], buckets)\n",
    "            for r in ranges:\n",
    "                data[f\"{column}%f_to_%f\" % r] = data[column].apply(\n",
    "                    lambda l: 1.0 if l >= r[0] and l < r[1] else 0.0)\n",
    "        data.drop(columns=[column], inplace=True)\n",
    "\n",
    "def bucketize_keep(data, columns):\n",
    "    for column, buckets in columns:\n",
    "        if data[column].dtypes == \"float64\":\n",
    "            ranges = get_bucket_boundaries(data[column], buckets)\n",
    "            for r in ranges:\n",
    "                data[f\"{column}%f_to_%f\" % r] = data[column].apply(\n",
    "                    lambda l: 1.0 if l >= r[0] and l < r[1] else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess__and_fit(num_buckets, keep=False):\n",
    "    housing = tmp_housing.copy()\n",
    "\n",
    "    columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
    "\n",
    "    buckets = np.empty(len(columns))\n",
    "    buckets.fill(num_buckets)\n",
    "\n",
    "    if keep:\n",
    "        bucketize_keep(housing, zip(columns, buckets))\n",
    "    else:\n",
    "        bucketize(housing, zip(columns, buckets))\n",
    "    \n",
    "    # First, extract the data into arrays\n",
    "    y = housing.median_house_value.values.reshape(-1,1)\n",
    "    X = housing.drop(columns=['median_house_value'], inplace=False).values\n",
    "    # Pull out 1000 values into a holdout set\n",
    "    holdout = random.sample(range(0,10640),1000)\n",
    "    X_holdout = X[holdout]\n",
    "    y_holdout = y[holdout]\n",
    "    Xt = np.delete(X, holdout, 0)\n",
    "    yt = np.delete(y, holdout, 0)\n",
    "\n",
    "    Model = lm.LinearRegression()\n",
    "    n_splits=10\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    train_err = 0\n",
    "    test_err = 0\n",
    "    test_err_deneg = 0\n",
    "    non_neg_count = 0\n",
    "    for train_index, test_index in kf.split(Xt):\n",
    "        X_train, X_test = Xt[train_index], Xt[test_index]\n",
    "        y_train, y_test = yt[train_index], yt[test_index]\n",
    "        Model.fit(X_train, y_train)\n",
    "        train_err += Model.score(X_train, y_train)\n",
    "        test = Model.score(X_test, y_test)\n",
    "        test_err += test\n",
    "        if(test > 0):\n",
    "            test_err_deneg += test\n",
    "            non_neg_count += 1\n",
    "        \n",
    "    print(\"\\nNumber of buckets: \" + str(num_buckets))\n",
    "    print('Average Training Error: ' + str(train_err / n_splits))\n",
    "    if(non_neg_count > 0):\n",
    "        print('Average Testing Error: ' + str(test_err_deneg / non_neg_count))\n",
    "    print('Negative results: ' + str(n_splits - non_neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of buckets: 1\n",
      "Average Training Error: 0.26122765530670167\n",
      "Average Testing Error: 0.2635063471885331\n",
      "Negative results: 4\n",
      "\n",
      "Number of buckets: 2\n",
      "Average Training Error: 0.46750257758015845\n",
      "Average Testing Error: 0.46111234334269197\n",
      "Negative results: 4\n",
      "\n",
      "Number of buckets: 4\n",
      "Average Training Error: 0.5900523997721289\n",
      "Average Testing Error: 0.5848649784238242\n",
      "Negative results: 3\n",
      "\n",
      "Number of buckets: 8\n",
      "Average Training Error: 0.6728780458699222\n",
      "Average Testing Error: 0.6683638297612626\n",
      "Negative results: 2\n",
      "\n",
      "Number of buckets: 16\n",
      "Average Training Error: 0.7216921025271169\n",
      "Average Testing Error: 0.7164246282233564\n",
      "Negative results: 4\n",
      "\n",
      "Number of buckets: 32\n",
      "Average Training Error: 0.7541922982308339\n",
      "Average Testing Error: 0.7451226687726715\n",
      "Negative results: 3\n",
      "\n",
      "Number of buckets: 64\n",
      "Average Training Error: 0.770395416651297\n",
      "Average Testing Error: 0.7550180986274012\n",
      "Negative results: 3\n",
      "\n",
      "Number of buckets: 128\n",
      "Average Training Error: 0.7805799717912072\n",
      "Average Testing Error: 0.7527295471039133\n",
      "Negative results: 2\n"
     ]
    }
   ],
   "source": [
    "#1 to 128 buckets per variable with only one-hot encodings\n",
    "for i in range(8):\n",
    "    preprocess__and_fit(2**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of buckets: 25\n",
      "Average Training Error: 0.7514140960856017\n",
      "Average Testing Error: 0.7446987931636696\n",
      "Negative results: 0\n"
     ]
    }
   ],
   "source": [
    "#25 Buckets per variable keeping original data.\n",
    "preprocess__and_fit(25, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "housing.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
